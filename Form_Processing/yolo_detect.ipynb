{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/amit/Projects/CTEVT/Form_Processing/RPL_processed_photo_processed/Plumber/bijaya/form.jpg: 640x480 2 persons, 932.3ms\n",
      "Speed: 3.9ms preprocess, 932.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "class ImageCropper:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def process_image(self, image_path: str, output_dir: str, classes=[1]):\n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Load image with cv2 for visualization\n",
    "        cv_image = cv2.imread(image_path)\n",
    "        # Load image with PIL for cropping\n",
    "        pil_image = Image.open(image_path)\n",
    "        \n",
    "        # Run detection\n",
    "        results = self.model(image_path, classes=classes, conf=0.2)\n",
    "        \n",
    "        # Process each detection\n",
    "        for idx, result in enumerate(results):\n",
    "            # result.show()\n",
    "            boxes = result.boxes.xyxy\n",
    "            \n",
    "            for box_idx, box in enumerate(boxes):\n",
    "                # Get original box coordinates and convert to integers\n",
    "                x1, y1, x2, y2 = map(int, box.tolist())\n",
    "                \n",
    "                # Draw original box in red (BGR format)\n",
    "                # cv2.rectangle(cv_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                \n",
    "                # Calculate padded coordinates\n",
    "                width = x2 - x1\n",
    "                height = y2 - y1\n",
    "                padded_x1 = max(0, x1 - int(width * 0.15))\n",
    "                padded_y1 = max(0, y1 - int(height * 0.15))\n",
    "                padded_x2 = min(cv_image.shape[1], x2 + int(width * 0.15))\n",
    "                padded_y2 = min(cv_image.shape[0], y2 + int(height * 0.15))\n",
    "                \n",
    "                \n",
    "                o_padded_x1 = max(0, x1 - int(width * 0.03))\n",
    "                o_padded_y1 = max(0, y1 - int(height * 0.03))\n",
    "                o_padded_x2 = min(cv_image.shape[1], x2 + int(width * 0.03))\n",
    "                o_padded_y2 = min(cv_image.shape[0], y2 + int(height * 0.03))\n",
    "                \n",
    "                # Draw padded box in green (BGR format)\n",
    "                # cv2.rectangle(cv_image, (padded_x1, padded_y1), (padded_x2, padded_y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Add labels with better positioning and background\n",
    "                # Original box label\n",
    "                # label = 'Original'\n",
    "                # (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "                # cv2.rectangle(cv_image, (x1, y1 - 20), (x1 + label_w, y1), (0, 0, 255), -1)\n",
    "                # cv2.putText(cv_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "                \n",
    "                # Padded box label\n",
    "                # label = 'Padded'\n",
    "                # (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "                # cv2.rectangle(cv_image, (padded_x1, padded_y1 - 20), (padded_x1 + label_w, padded_y1), (0, 255, 0), -1)\n",
    "                # cv2.putText(cv_image, label, (padded_x1, padded_y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "                \n",
    "                # Crop and save using padded coordinates (using PIL for consistency)\n",
    "                cropped = cv_image[padded_y1:padded_y2, padded_x1:padded_x2]\n",
    "                crop_no_pad = cv_image[o_padded_y1:o_padded_y2, o_padded_x1:o_padded_x2]\n",
    "\n",
    "                output_path = os.path.join(output_dir, f\"backup_{idx + 1}_{box_idx + 1}.jpg\")\n",
    "                cv2.imwrite(output_path, cropped, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "                \n",
    "                output_path = os.path.join(output_dir, f\"photo_{idx + 1}_{box_idx + 1}.jpg\")\n",
    "                cv2.imwrite(output_path, crop_no_pad, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "        \n",
    "        # Save the visualization\n",
    "        viz_path = os.path.join(output_dir, \"boxes_visualization.jpg\")\n",
    "        cv2.imwrite(viz_path, cv_image)\n",
    "\n",
    "def main():\n",
    "    cropper = ImageCropper(\"yolo11x.pt\")\n",
    "    cropper.process_image(\n",
    "        image_path=\"RPL_processed_photo_processed/Plumber/bijaya/form.jpg\",\n",
    "        output_dir=\"output_dir\",\n",
    "        classes=[0]  # Person class\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
