{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/amit/Projects/CTEVT/Form_Processing/RPL_processed_photo_processed/Plumber/bijaya/form.jpg: 640x480 2 persons, 974.6ms\n",
      "Speed: 4.7ms preprocess, 974.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "class ImageCropper:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def process_image(self, image_path: str, output_dir: str, classes=[1]):\n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Load image with cv2 for visualization\n",
    "        cv_image = cv2.imread(image_path)\n",
    "        # Load image with PIL for cropping\n",
    "        pil_image = Image.open(image_path)\n",
    "        \n",
    "        # Run detection\n",
    "        results = self.model(image_path, classes=classes, conf=0.2)\n",
    "        \n",
    "        # Process each detection\n",
    "        for idx, result in enumerate(results):\n",
    "            # result.show()\n",
    "            boxes = result.boxes.xyxy\n",
    "            \n",
    "            for box_idx, box in enumerate(boxes):\n",
    "                # Get original box coordinates and convert to integers\n",
    "                x1, y1, x2, y2 = map(int, box.tolist())\n",
    "                \n",
    "                # Draw original box in red (BGR format)\n",
    "                # cv2.rectangle(cv_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                \n",
    "                # Calculate padded coordinates\n",
    "                width = x2 - x1\n",
    "                height = y2 - y1\n",
    "                padded_x1 = max(0, x1 - int(width * 0.1))\n",
    "                padded_y1 = max(0, y1 - int(height * 0.1))\n",
    "                padded_x2 = min(cv_image.shape[1], x2 + int(width * 0.1))\n",
    "                padded_y2 = min(cv_image.shape[0], y2 + int(height * 0.1))\n",
    "                \n",
    "                # Draw padded box in green (BGR format)\n",
    "                # cv2.rectangle(cv_image, (padded_x1, padded_y1), (padded_x2, padded_y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Add labels with better positioning and background\n",
    "                # Original box label\n",
    "                # label = 'Original'\n",
    "                # (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "                # cv2.rectangle(cv_image, (x1, y1 - 20), (x1 + label_w, y1), (0, 0, 255), -1)\n",
    "                # cv2.putText(cv_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "                \n",
    "                # Padded box label\n",
    "                # label = 'Padded'\n",
    "                # (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "                # cv2.rectangle(cv_image, (padded_x1, padded_y1 - 20), (padded_x1 + label_w, padded_y1), (0, 255, 0), -1)\n",
    "                # cv2.putText(cv_image, label, (padded_x1, padded_y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "                \n",
    "                # Crop and save using padded coordinates (using PIL for consistency)\n",
    "                cropped = cv_image[padded_y1:padded_y2, padded_x1:padded_x2]\n",
    "\n",
    "                output_path = os.path.join(output_dir, f\"crop_{idx + 1}_{box_idx + 1}.jpg\")\n",
    "                cv2.imwrite(output_path, cropped, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "        \n",
    "        # Save the visualization\n",
    "        viz_path = os.path.join(output_dir, \"boxes_visualization.jpg\")\n",
    "        cv2.imwrite(viz_path, cv_image)\n",
    "\n",
    "def main():\n",
    "    cropper = ImageCropper(\"yolo11x.pt\")\n",
    "    cropper.process_image(\n",
    "        image_path=\"RPL_processed_photo_processed/Plumber/bijaya/form.jpg\",\n",
    "        output_dir=\"output_dir\",\n",
    "        classes=[0]  # Person class\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/amit/Projects/CTEVT/Form_Processing/RPL_processed_photo_processed/Mason/man_bahadur/form.jpg: 1024x672 224346.5ms\n",
      "Speed: 1362.9ms preprocess, 224346.5ms inference, 70.9ms postprocess per image at shape (1, 3, 1024, 672)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'xyxy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 137\u001b[0m\n\u001b[1;32m    130\u001b[0m     cropper\u001b[38;5;241m.\u001b[39mprocess_image(\n\u001b[1;32m    131\u001b[0m         image_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPL_processed_photo_processed/Mason/man_bahadur/form.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    132\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m         classes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Person class\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     )\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 130\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m    129\u001b[0m     cropper \u001b[38;5;241m=\u001b[39m ImageCropper(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11x-obb.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 130\u001b[0m     \u001b[43mcropper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRPL_processed_photo_processed/Mason/man_bahadur/form.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Person class\u001b[39;49;00m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 55\u001b[0m, in \u001b[0;36mImageCropper.process_image\u001b[0;34m(self, image_path, output_dir, classes)\u001b[0m\n\u001b[1;32m     51\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(image_path, classes\u001b[38;5;241m=\u001b[39mclasses, conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Get both regular boxes and rotation angles\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxyxy\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Check if the model outputs rotation angles\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mboxes, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mang\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'xyxy'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import math\n",
    "\n",
    "class ImageCropper:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def rotate_box(self, image, box, angle_deg):\n",
    "        \"\"\"Rotate a bounding box around its center.\"\"\"\n",
    "        # Convert angle to radians\n",
    "        angle_rad = math.radians(angle_deg)\n",
    "        \n",
    "        # Get box center\n",
    "        cx = (box[0] + box[2]) / 2\n",
    "        cy = (box[1] + box[3]) / 2\n",
    "        \n",
    "        # Get box width and height\n",
    "        width = box[2] - box[0]\n",
    "        height = box[3] - box[1]\n",
    "        \n",
    "        # Create rotation matrix\n",
    "        rotation_matrix = cv2.getRotationMatrix2D((cx, cy), angle_deg, 1.0)\n",
    "        \n",
    "        # Get corners of the box\n",
    "        corners = np.array([\n",
    "            [box[0], box[1]],\n",
    "            [box[2], box[1]],\n",
    "            [box[2], box[3]],\n",
    "            [box[0], box[3]]\n",
    "        ])\n",
    "        \n",
    "        # Rotate corners\n",
    "        ones = np.ones(shape=(len(corners), 1))\n",
    "        corners_ones = np.hstack([corners, ones])\n",
    "        rotated_corners = rotation_matrix.dot(corners_ones.T).T\n",
    "        \n",
    "        return rotated_corners\n",
    "\n",
    "    def process_image(self, image_path: str, output_dir: str, classes=[1]):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Load images\n",
    "        cv_image = cv2.imread(image_path)\n",
    "        pil_image = Image.open(image_path)\n",
    "        \n",
    "        # Run detection\n",
    "        results = self.model(image_path, classes=classes, conf=0.2)\n",
    "        \n",
    "        for idx, result in enumerate(results):\n",
    "            # Get both regular boxes and rotation angles\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()\n",
    "            # Check if the model outputs rotation angles\n",
    "            if hasattr(result.boxes, 'ang'):\n",
    "                angles = result.boxes.ang.cpu().numpy()\n",
    "            else:\n",
    "                angles = np.zeros(len(boxes))  # Default to 0 if no angle information\n",
    "            \n",
    "            for box_idx, (box, angle) in enumerate(zip(boxes, angles)):\n",
    "                x1, y1, x2, y2 = map(int, box.tolist())\n",
    "                \n",
    "                # Get rotated corners\n",
    "                rotated_corners = self.rotate_box(cv_image, box, angle)\n",
    "                \n",
    "                # Draw original oriented box in red\n",
    "                corners_int = rotated_corners.astype(np.int32)\n",
    "                cv2.polylines(cv_image, [corners_int], True, (0, 0, 255), 2)\n",
    "                \n",
    "                # Calculate padded box with rotation\n",
    "                width = x2 - x1\n",
    "                height = y2 - y1\n",
    "                padding_x = int(width * 0.1)\n",
    "                padding_y = int(height * 0.1)\n",
    "                \n",
    "                padded_box = [\n",
    "                    x1 - padding_x,\n",
    "                    y1 - padding_y,\n",
    "                    x2 + padding_x,\n",
    "                    y2 + padding_y\n",
    "                ]\n",
    "                \n",
    "                # Get padded rotated corners\n",
    "                padded_rotated_corners = self.rotate_box(cv_image, padded_box, angle)\n",
    "                \n",
    "                # Draw padded oriented box in green\n",
    "                padded_corners_int = padded_rotated_corners.astype(np.int32)\n",
    "                cv2.polylines(cv_image, [padded_corners_int], True, (0, 255, 0), 2)\n",
    "                \n",
    "                # Create a rotation matrix for the crop\n",
    "                center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                rotation_matrix = cv2.getRotationMatrix2D(center, -angle, 1.0)\n",
    "                \n",
    "                # Rotate the image\n",
    "                rotated_image = cv2.warpAffine(\n",
    "                    cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR),\n",
    "                    rotation_matrix,\n",
    "                    (cv_image.shape[1], cv_image.shape[0])\n",
    "                )\n",
    "                \n",
    "                # Crop the rotated image\n",
    "                padded_crop = rotated_image[\n",
    "                    max(0, int(y1 - padding_y)):min(rotated_image.shape[0], int(y2 + padding_y)),\n",
    "                    max(0, int(x1 - padding_x)):min(rotated_image.shape[1], int(x2 + padding_x))\n",
    "                ]\n",
    "                \n",
    "                # Save the cropped image\n",
    "                output_path = os.path.join(output_dir, f\"crop_{idx + 1}_{box_idx + 1}.jpg\")\n",
    "                cv2.imwrite(output_path, padded_crop)\n",
    "                \n",
    "                # Add labels\n",
    "                self._add_label(cv_image, rotated_corners[0], \"Original\", (0, 0, 255))\n",
    "                self._add_label(cv_image, padded_rotated_corners[0], \"Padded\", (0, 255, 0))\n",
    "        \n",
    "        # # Save visualization\n",
    "        # viz_path = os.path.join(output_dir, \"boxes_visualization.jpg\")\n",
    "        # cv2.imwrite(viz_path, cv_image)\n",
    "\n",
    "    def _add_label(self, image, position, text, color):\n",
    "        \"\"\"Helper method to add labels with background.\"\"\"\n",
    "        x, y = map(int, position)\n",
    "        (label_w, label_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "        cv2.rectangle(image, (x, y - 20), (x + label_w, y), color, -1)\n",
    "        cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "def main():\n",
    "    cropper = ImageCropper(\"yolo11x-obb.pt\")\n",
    "    cropper.process_image(\n",
    "        image_path=\"RPL_processed_photo_processed/Mason/man_bahadur/form.jpg\",\n",
    "        output_dir=\"output_dir\",\n",
    "        classes=[0]  # Person class\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
